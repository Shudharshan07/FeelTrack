{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "\n",
    "class Sentiment_Analysis():\n",
    "    def __init__(self,alpha = 1.0):\n",
    "        self.alpha = alpha\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.Class_Probability = [0,0,0,0,0,0]\n",
    "        self.Class = {\n",
    "            \"fear\" : 0,\n",
    "            \"sad\" : 1,\n",
    "            \"anger\" : 2,\n",
    "            \"love\" : 3,\n",
    "            \"suprise\" : 4,\n",
    "            \"joy\" :5\n",
    "        }\n",
    "        self.Vocabulary = {}\n",
    "        self.StopWords = [\"i\", \"\",\"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\",\n",
    "            \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\",\n",
    "            \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\",\n",
    "            \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\",\n",
    "            \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\",\"of\", \"at\", \"by\", \"for\", \"with\", \n",
    "            \"about\",\"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"over\", \"under\", \"again\",\n",
    "            \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\",\n",
    "            \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"nor\", \"only\", \"own\", \"same\", \"so\",\n",
    "            \"than\", \"can\", \"will\", \"just\", \"now\",\"do\"]\n",
    "\n",
    "    def Process(self,current, end,rate):\n",
    "        percentage = 100 * (current/end)\n",
    "        bar = \"#\" * int(percentage/2) + \"-\" * (50 - int(percentage/2))\n",
    "\n",
    "        print(f\"\\r| {bar} | , {percentage: .2f} , {rate: .2f}\",end=\"\\r\")\n",
    "\n",
    "    def Train(self,Data,max_count):\n",
    "        count = 0\n",
    "        for ind,line in Data.iterrows():\n",
    "            start = time.perf_counter()\n",
    "            words = self.Tokeniser(line[0])\n",
    "            class_index = self.Class[line[1]]\n",
    "            for word in words:\n",
    "                if word not in self.Vocabulary:\n",
    "                    self.Vocabulary[word] = [0,0,0,0,0,0]\n",
    "                \n",
    "                (self.Vocabulary[word])[class_index]+=1\n",
    "                self.Class_Probability[class_index]+=1\n",
    "            end = time.perf_counter()\n",
    "            count+=1\n",
    "            self.Process(count,max_count,(end-start)*(max_count-count))\n",
    "            if(count == max_count):\n",
    "                break\n",
    "        V = len(self.Vocabulary)\n",
    "\n",
    "        for i in range(0,6):\n",
    "            for word in self.Vocabulary:\n",
    "                (self.Vocabulary[word])[i] = (((self.Vocabulary[word])[i] + self.alpha)/(self.Class_Probability[i] + (V*(self.alpha))))\n",
    "\n",
    "        tmp = sum(self.Class_Probability)\n",
    "        for i in range(0,6):\n",
    "            self.Class_Probability[i] = (self.Class_Probability[i])/tmp\n",
    "\n",
    "\n",
    "    def Test(self,TestData,max_count):\n",
    "        score = 0\n",
    "        count = 0\n",
    "        for ind,text in TestData.iterrows():\n",
    "            start = time.perf_counter()\n",
    "            words = self.Tokeniser(text[0])\n",
    "\n",
    "            Scores = [0]*6\n",
    "            for i in range(0,6):\n",
    "                Scores[i] = math.log(self.Class_Probability[i])\n",
    "\n",
    "            for word in words:\n",
    "                if word in self.Vocabulary:\n",
    "                    word_probability = self.Vocabulary[word]\n",
    "                    for i in range(0,6):\n",
    "                        Scores[i] += (math.log(word_probability[i]))\n",
    "\n",
    "    \n",
    "            if self.Class[text[1]] == Scores.index(max(Scores)):\n",
    "                score+=1\n",
    "\n",
    "            count+=1\n",
    "            end = time.perf_counter()\n",
    "            self.Process(count,max_count,(end-start)*(max_count-count))\n",
    "\n",
    "            if count == max_count:\n",
    "                break\n",
    "        \n",
    "        return (100 * (score/max_count))\n",
    "    \n",
    "\n",
    "    def Predit(self,text):\n",
    "        words = self.Tokeniser(text)\n",
    "        Score = [0,0,0,0,0,0]\n",
    "        for i in range(0,6):\n",
    "            Score[i] = self.Class_Probability[i]\n",
    "\n",
    "        for word in words:\n",
    "            if word in self.Vocabulary:\n",
    "                for i in range(0,6):\n",
    "                    Score[i] += math.log((self.Vocabulary[word])[i])\n",
    "\n",
    "        return Score\n",
    "            \n",
    "                       \n",
    "    def lemmatization(self,word):\n",
    "        return self.nlp(word)[0].lemma_\n",
    "\n",
    "    def Tokeniser(self,text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        text = list(set(text.split(\" \")))\n",
    "        text = [self.lemmatization(tex) for tex in text if tex not in self.StopWords]\n",
    "        return text\n",
    "\n",
    "a = Sentiment_Analysis(1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NEXT GEN\\AppData\\Local\\Temp\\ipykernel_13968\\4128354281.py:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  words = self.Tokeniser(line[0])\n",
      "C:\\Users\\NEXT GEN\\AppData\\Local\\Temp\\ipykernel_13968\\4128354281.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  class_index = self.Class[line[1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ################################################## | ,  100.00 ,  0.004522\r"
     ]
    }
   ],
   "source": [
    "DataSet = pd.read_csv(\"train.csv\")\n",
    "\n",
    "a.Train(DataSet,317058)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NEXT GEN\\AppData\\Local\\Temp\\ipykernel_13968\\4128354281.py:70: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  words = self.Tokeniser(text[0])\n",
      "C:\\Users\\NEXT GEN\\AppData\\Local\\Temp\\ipykernel_13968\\4128354281.py:83: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if self.Class[text[1]] == Scores.index(max(Scores)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ################################################## | ,  100.00 ,  0.00\n",
      " 90.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(f\"\\n {a.Test(Test,100)} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sc = a.Predit(\"ima hate you\")\n",
    "\n",
    "ind = sc.index(max(sc))\n",
    "\n",
    "\n",
    "if ind == 0:\n",
    "    print(\"fear\")\n",
    "elif ind == 1:\n",
    "    print(\"sad\")\n",
    "elif ind == 2:\n",
    "    print(\"anger\")\n",
    "elif ind == 3:\n",
    "    print(\"love\")\n",
    "elif ind == 4:\n",
    "    print(\"suprise\")\n",
    "else:\n",
    "    print(\"joy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"model.pkl\",\"wb\") as f:\n",
    "    pickle.dump(a,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
